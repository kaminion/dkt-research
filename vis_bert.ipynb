{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpreting BERT Models with Captum library\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module\n",
    "from models.dkvmn_text import SUBJ_DKVMN\n",
    "\n",
    "from data_loaders.assist2009 import ASSIST2009\n",
    "from data_loaders.assist2012 import ASSIST2012\n",
    "from data_loaders.csedm import CSEDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "model_name = \"dkvmn+\"\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "dataset_name = \"ASSIST2009\"\n",
    "ckpts = f\"ckpts/{model_name}/{dataset_name}/\"\n",
    "\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "    model_config = config[model_name]\n",
    "    train_config = config[\"train_config\"]\n",
    "    \n",
    "batch_size = train_config[\"batch_size\"]\n",
    "num_epochs = train_config[\"num_epochs\"]\n",
    "train_ratio = train_config[\"train_ratio\"]\n",
    "learning_rate = train_config[\"learning_rate\"]\n",
    "optimizer = train_config[\"optimizer\"] # can be sgd, adam\n",
    "seq_len = train_config[\"seq_len\"] # 샘플링 할 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, CharTensor, LongTensor\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    from torch import FloatTensor, CharTensor, LongTensor\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('./ckpts/tokenizer/ASSIST2009/DISTIL_A2009')\n",
    "\n",
    "def custom_collate(batch, pad_val=-1):\n",
    "    '''\n",
    "    This function for torch.utils.data.DataLoader\n",
    "\n",
    "    Returns:\n",
    "        q_seqs: the question(KC) sequences with the size of \\\n",
    "            [batch_size, maximum_sequence_length_in_the_batch]\n",
    "        r_seqs: the response sequences with the size of \\\n",
    "            [batch_size, maximum_sequence_length_in_the_batch]\n",
    "        qshft_seqs: the question(KC) sequences which were shifted \\\n",
    "            one step to the right with the size of \\\n",
    "            [batch_size, maximum_sequence_length_in_the_batch]\n",
    "        rshft_seqs: the response sequences which were shifted \\\n",
    "            one step to the right with the size of \\\n",
    "            [batch_size, maximum_sequence_length_in_the_batch]\n",
    "        mask_seqs: the mask sequences indicating where \\\n",
    "            the padded entry is with the size of \\\n",
    "            [batch_size, maximum_sequence_length_in_the_batch]\n",
    "    '''\n",
    "\n",
    "    q_seqs = []\n",
    "    r_seqs = []\n",
    "    qshft_seqs = []\n",
    "    rshft_seqs = []\n",
    "    at_seqs = []\n",
    "    atshft_seqs = []\n",
    "    q2diff_seqs = []\n",
    "    pid_seqs = []\n",
    "    pidshft_seqs = []\n",
    "    hint_seqs = []\n",
    "\n",
    "    # q_seq와 r_seq는 마지막 전까지만 가져옴 (마지막은 padding value)\n",
    "    # q_shft와 rshft는 처음 값 이후 가져옴 (우측 시프트 값이므로..)\n",
    "    for q_seq, r_seq, at_seq, q2diff, pid_seq, hint_seq in batch:\n",
    "        q_seqs.append(FloatTensor(q_seq[:-1])) \n",
    "        r_seqs.append(FloatTensor(r_seq[:-1]))\n",
    "        at_seqs.append(at_seq[:-1])\n",
    "        atshft_seqs.append(at_seq[1:])\n",
    "        qshft_seqs.append(FloatTensor(q_seq[1:]))\n",
    "        rshft_seqs.append(FloatTensor(r_seq[1:]))\n",
    "        q2diff_seqs.append(FloatTensor(q2diff[:-1]))\n",
    "        pid_seqs.append(FloatTensor(pid_seq[:-1]))\n",
    "        pidshft_seqs.append(FloatTensor(pid_seq[1:]))\n",
    "        hint_seqs.append(FloatTensor(hint_seq[:-1]))\n",
    "\n",
    "    # pad_sequence, 첫번째 인자는 sequence, 두번째는 batch_size가 첫 번째로 인자로 오게 하는 것이고, 3번째 인자의 경우 padding된 요소의 값\n",
    "    # 시퀀스 내 가장 길이가 긴 시퀀스를 기준으로 padding이 됨, 길이가 안맞는 부분은 늘려서 padding_value 값으로 채워줌\n",
    "    q_seqs = pad_sequence(\n",
    "        q_seqs, batch_first=True, padding_value=pad_val\n",
    "    )\n",
    "    r_seqs = pad_sequence(\n",
    "        r_seqs, batch_first=True, padding_value=pad_val\n",
    "    )\n",
    "    q2diff_seqs = pad_sequence(\n",
    "        q2diff_seqs, batch_first=True, padding_value=pad_val\n",
    "    )\n",
    "    qshft_seqs = pad_sequence(\n",
    "        qshft_seqs, batch_first=True, padding_value=pad_val\n",
    "    )\n",
    "    rshft_seqs = pad_sequence(\n",
    "        rshft_seqs, batch_first=True, padding_value=pad_val\n",
    "    )\n",
    "    pid_seqs = pad_sequence(\n",
    "        pid_seqs, batch_first=True, padding_value=pad_val\n",
    "    )\n",
    "    pidshft_seqs = pad_sequence(\n",
    "        pidshft_seqs, batch_first=True, padding_value=pad_val\n",
    "    )\n",
    "    hint_seqs = pad_sequence(\n",
    "        hint_seqs, batch_first=True, padding_value=pad_val\n",
    "    )\n",
    "\n",
    "    # 마스킹 시퀀스 생성 \n",
    "    # 일반 question 시퀀스: 패딩 밸류와 다른 값들은 모두 1로 처리, 패딩 처리된 값들은 0으로 처리.\n",
    "    # 일반 question padding 시퀀스: 한 칸 옆으로 시프팅 된 시퀀스 값들이 패딩 값과 다를 경우 1로 처리, 패딩 처리 된 값들은 0으로 처리.\n",
    "    # 마스킹 시퀀스: 패딩 처리 된 시퀀스 밸류들은 모두 0, 두 값 모두 패딩처리 되지 않았을 경우 1로 처리. (원본 시퀀스와 shift 시퀀스 모두의 값)\n",
    "    # 예를 들어, 현재 값과 다음 값이 패딩 값이 아닐 경우 1, 현재 값과 다음 값 둘 중 하나라도 패딩일 경우 0으로 처리함.\n",
    "    mask_seqs = (q_seqs != pad_val) * (qshft_seqs != pad_val)\n",
    "\n",
    "    # 원본 값의 다음 값이(shift value) 패딩이기만 해도 마스킹 시퀀스에 의해 값이 0로 변함. 아닐경우 원본 시퀀스 데이터를 가짐.\n",
    "    q_seqs, r_seqs, qshft_seqs, rshft_seqs, q2diff_seqs, pid_seqs, pidshft_seqs, hint_seqs = \\\n",
    "        q_seqs * mask_seqs, r_seqs * mask_seqs, qshft_seqs * mask_seqs, \\\n",
    "        rshft_seqs * mask_seqs, q2diff_seqs * mask_seqs, pid_seqs * mask_seqs, \\\n",
    "        pidshft_seqs * mask_seqs, hint_seqs * mask_seqs\n",
    "    \n",
    "\n",
    "    # Word2vec\n",
    "\n",
    "    # BERT preprocessing\n",
    "    bert_details = []\n",
    "\n",
    "    # def mapmax(data):\n",
    "    #     return max(data, key=len)\n",
    "\n",
    "    # 2차원에서 가장 긴 문장 추출\n",
    "    # SENT_LEN = len(max(map(mapmax, at_seqs), key=len))\n",
    "\n",
    "    for answer_text in at_seqs:\n",
    "        text = list(map(str, answer_text))\n",
    "        # print(f\"============= text: {text} ================\")\n",
    "        \n",
    "        encoded_bert_sent = tokenizer.encode_plus(\n",
    "            text, add_special_tokens=False, padding=\"max_length\", max_len=200, truncation=True\n",
    "        )\n",
    "        bert_details.append(encoded_bert_sent)\n",
    "    \n",
    "    # 정답지 추가\n",
    "    # proc_atshft_seqs = []\n",
    "    # # SENT_LEN = q_seqs.size(0)\n",
    "    # for answer_text in atshft_seqs:\n",
    "    #     text = \" \".join(map(str, answer_text))\n",
    "    #     encoded_bert_sent = bert_tokenizer.encode_plus(\n",
    "    #         text, add_special_tokens=True, padding='max_length', truncation=True\n",
    "    #     )\n",
    "    #     proc_atshft_seqs.append(encoded_bert_sent)\n",
    "\n",
    "    bert_sentences = LongTensor([text[\"input_ids\"] for text in bert_details])\n",
    "    # bert_sentence_types = LongTensor([text[\"token_type_ids\"] for text in bert_details])\n",
    "    bert_sentence_att_mask = LongTensor([text[\"attention_mask\"] for text in bert_details])\n",
    "    # proc_atshft_sentences = LongTensor([text[\"input_ids\"] for text in proc_atshft_seqs])\n",
    "\n",
    "    return q_seqs, r_seqs, qshft_seqs, rshft_seqs, mask_seqs, bert_sentences, [], bert_sentence_att_mask, q2diff_seqs, pid_seqs, pidshft_seqs, at_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "# 데이터셋 추가 가능\n",
    "collate_pt = custom_collate\n",
    "dataset = ASSIST2009(seq_len, 'datasets/ASSIST2009/')\n",
    "if dataset_name == \"ASSIST2012\":\n",
    "    dataset = ASSIST2012(seq_len, 'datasets/ASSIST2012/')\n",
    "elif dataset_name == \"CSEDM\":\n",
    "    dataset = CSEDM(seq_len, 'datasets/CSEDM/')\n",
    "    \n",
    "# 데이터셋 분할\n",
    "data_size = len(dataset)\n",
    "train_size = int(data_size * train_ratio) \n",
    "valid_size = int(data_size * ((1.0 - train_ratio) / 2.0))\n",
    "test_size = data_size - train_size - valid_size\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, valid_size, test_size], generator=torch.Generator(device=device)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=collate_pt, generator=torch.Generator(device=device)\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=collate_pt, generator=torch.Generator(device=device)\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=collate_pt, generator=torch.Generator(device=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dim_s': 200, 'size_m': 20}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define help function\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpts/dkvmn+/ASSIST2009/\n"
     ]
    }
   ],
   "source": [
    "# load model / tokenizer in collate function\n",
    "print(ckpts)\n",
    "model = torch.nn.DataParallel(SUBJ_DKVMN(dataset.num_q, num_qid=dataset.num_pid, **model_config)).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(ckpts, \"model.ckpt\"), map_location=device))\n",
    "model.eval()\n",
    "model.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict answer (testing model)\n",
    "def predict(q, r, at_s, at_t, at_m):\n",
    "    output, Mv = model(q, r, at_s, at_t, at_m)\n",
    "    return output\n",
    "\n",
    "# custom forward function\n",
    "def custom_forward(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0):\n",
    "    pred = predict(inputs, position_ids, token_type_ids, attention_mask)\n",
    "    pred = pred[position]\n",
    "    return pred.max(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "cls_token_id = tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper function for constructing references / baseline for word tokens\n",
    "# 이게 원래 인풋으로 들어가는 Question과 아웃풋의 Answering이 존재했는데 나는 Answering 안써서 Answering 제거함\n",
    "def construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id):\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False, max_length=200, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
    "    \n",
    "    # construct reference token ids\n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "    \n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(text_ids)\n",
    "\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device) # * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with 'torch.randperm(seq_length, device=device)'\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "    \n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "\n",
    "\n",
    "# 어텐션 마스크 구성\n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "\n",
    "# 버트 임베딩 구성\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.module.bertmodel.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.module.bertmodel.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings\n",
    "\n",
    "\n",
    "# 시퀀스에서 각 워드 토큰에 대해 속성을 요약해주는 헬퍼 함수\n",
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 Interpreting text models tutorial 보고 진행\n",
    "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta):\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.cpu().detach().numpy()\n",
    "\n",
    "    print(attributions)\n",
    "\n",
    "    end_position_vis = viz.VisualizationDataRecord(\n",
    "        attributions, # word_attributions\n",
    "        pred, # pred_prob\n",
    "        pred_ind, # pred_class\n",
    "        label, # true_class\n",
    "        str(pred_ind),  # attr_class\n",
    "        attributions.sum(), # attr_score\n",
    "        text, # row_input_ids\n",
    "        delta # convergence_score\n",
    "    )\n",
    "    viz.visualize_text([end_position_vis])\n",
    "\n",
    "def interpret_sentence(model, q, r, input_ids, token_type_ids, attention_mask):\n",
    "    model.zero_grad()\n",
    "\n",
    "    input_indices = input_ids\n",
    "    # input_indices = input_indices.unsqueeze(0)\n",
    "    print(input_indices.shape)\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(input_indices[1])\n",
    "\n",
    "    # predict\n",
    "    pred = predict(q.long(), r.long(), input_ids, token_type_ids, attention_mask)\n",
    "    pred_ind = torch.round(pred)\n",
    "    \n",
    "    # compute attributions and approximation delta using layer integrated gradients\n",
    "    lig = LayerIntegratedGradients(predict, model.module.bertmodel.embeddings)\n",
    "    ig, delta = lig.attribute((q.long()), additional_forward_args=(r.long(), input_ids, token_type_ids, attention_mask), \\\n",
    "                                    return_convergence_delta=True, n_steps=10, internal_batch_size=16, target=1)\n",
    "    print(pred_ind.shape, pred.shape, delta.shape)\n",
    "    print(f\"pred: {pred_ind[0]} pred %: {pred[0]} delta: {abs(delta[0])} \")\n",
    "\n",
    "    add_attributions_to_visualizer(ig, all_tokens, pred[0], pred_ind[0], r, delta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n",
      "torch.Size([16, 200]) torch.Size([16, 200]) torch.Size([16])\n",
      "pred: tensor([1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.]) pred %: tensor([7.7571e-01, 9.9416e-01, 1.9408e-02, 7.3560e-01, 9.6002e-05, 1.0633e-04,\n",
      "        4.9856e-05, 6.4436e-06, 3.5368e-06, 3.0966e-06, 9.7639e-07, 1.9060e-06,\n",
      "        7.2781e-07, 7.4105e-05, 1.5921e-05, 3.3070e-05, 4.8085e-04, 6.7363e-04,\n",
      "        5.3733e-05, 8.1087e-04, 3.8801e-05, 1.4498e-06, 6.2015e-05, 2.2521e-03,\n",
      "        1.0266e-03, 1.1136e-05, 8.8274e-05, 8.7643e-04, 4.5638e-06, 1.4139e-05,\n",
      "        9.0190e-04, 1.1954e-05, 4.9892e-06, 6.8427e-06, 1.0461e-04, 7.9399e-06,\n",
      "        1.8829e-05, 5.8154e-06, 3.3864e-05, 4.1814e-04, 2.9721e-06, 1.0779e-05,\n",
      "        1.2442e-05, 2.3757e-05, 1.8877e-05, 2.6051e-05, 8.7829e-06, 4.3784e-06,\n",
      "        2.9381e-06, 3.0305e-05, 4.6535e-03, 5.7524e-04, 8.8520e-05, 2.8010e-04,\n",
      "        2.2771e-04, 1.1407e-05, 2.7598e-06, 3.7140e-05, 8.8541e-06, 2.7815e-05,\n",
      "        1.4921e-04, 2.5254e-05, 9.7012e-05, 8.1070e-06, 6.5414e-05, 1.1570e-04,\n",
      "        2.0148e-05, 7.7333e-06, 1.4996e-05, 3.4773e-05, 3.9543e-05, 1.8082e-06,\n",
      "        3.1156e-06, 2.0524e-06, 5.2678e-05, 5.9571e-05, 6.0095e-05, 3.7177e-05,\n",
      "        3.4533e-03, 1.4136e-05, 1.1699e-04, 2.1283e-05, 1.1477e-03, 4.0471e-05,\n",
      "        2.1530e-05, 5.7706e-05, 1.3273e-06, 2.9445e-06, 5.5223e-04, 5.7607e-05,\n",
      "        2.9268e-04, 6.0447e-04, 3.6354e-05, 3.7265e-05, 1.7425e-05, 8.4866e-06,\n",
      "        9.2530e-06, 6.4403e-04, 3.6082e-05, 9.9593e-05, 3.0909e-03, 2.2910e-05,\n",
      "        2.4058e-05, 3.2302e-03, 1.1757e-05, 7.6358e-04, 1.5836e-04, 1.2537e-03,\n",
      "        2.9035e-03, 1.5927e-03, 1.6571e-04, 9.4924e-03, 1.8753e-03, 4.1040e-03,\n",
      "        9.0047e-04, 6.6254e-04, 2.1505e-04, 6.9108e-03, 1.7189e-02, 6.0507e-04,\n",
      "        8.9565e-05, 8.1057e-05, 2.0509e-05, 4.0968e-04, 1.7490e-04, 5.2945e-05,\n",
      "        2.3941e-05, 5.8433e-05, 3.4121e-06, 6.0776e-06, 2.1134e-06, 3.3499e-05,\n",
      "        4.3002e-04, 5.1311e-04, 4.2931e-05, 9.6420e-05, 1.8995e-06, 4.6899e-05,\n",
      "        3.3662e-05, 9.9563e-06, 1.1056e-03, 7.8842e-04, 6.6378e-04, 4.0847e-02,\n",
      "        1.6107e-02, 2.7991e-02, 9.5445e-05, 2.6045e-04, 2.8272e-04, 2.8123e-05,\n",
      "        3.3657e-06, 1.1201e-05, 3.0746e-04, 1.9216e-04, 3.2411e-03, 6.0259e-03,\n",
      "        8.5042e-03, 4.0846e-05, 3.5924e-05, 2.9161e-06, 5.9684e-04, 1.4761e-01,\n",
      "        7.5187e-03, 6.6179e-02, 8.0280e-03, 8.2359e-04, 1.7561e-05, 2.3483e-02,\n",
      "        3.6329e-03, 2.4861e-03, 3.7727e-02, 4.3168e-03, 3.5625e-02, 3.1393e-01,\n",
      "        7.5789e-02, 1.3645e-03, 1.8231e-02, 1.6959e-03, 4.2737e-04, 3.6658e-05,\n",
      "        4.6491e-05, 6.2126e-05, 2.7922e-06, 8.8132e-06, 4.2634e-05, 4.4297e-04,\n",
      "        1.6552e-04, 3.7428e-05, 8.2635e-04, 1.5214e-04, 4.3326e-05, 4.4849e-05,\n",
      "        6.4060e-03, 1.0184e-02, 2.0415e-03, 6.7141e-04, 2.2407e-04, 1.4743e-03,\n",
      "        2.4424e-05, 2.7282e-05]) delta: 0.005207240581512451 \n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Tensor.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_loader):\n\u001b[1;32m      3\u001b[0m     q, r, qshft_seqs, rshft_seqs, mask_seqs, input_ids, token_type_ids, attention_mask, q2diff_seqs, pid_seqs, pidshft_seqs, at_seqs \\\n\u001b[1;32m      4\u001b[0m         \u001b[39m=\u001b[39m data\n\u001b[0;32m----> 6\u001b[0m     interpret_sentence(model, q, r, input_ids, token_type_ids, attention_mask)\n\u001b[1;32m      8\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 40\u001b[0m, in \u001b[0;36minterpret_sentence\u001b[0;34m(model, q, r, input_ids, token_type_ids, attention_mask)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mprint\u001b[39m(pred_ind\u001b[39m.\u001b[39mshape, pred\u001b[39m.\u001b[39mshape, delta\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     38\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpred: \u001b[39m\u001b[39m{\u001b[39;00mpred_ind[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m pred %: \u001b[39m\u001b[39m{\u001b[39;00mpred[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m delta: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mabs\u001b[39m(delta[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m add_attributions_to_visualizer(ig, all_tokens, pred[\u001b[39m0\u001b[39;49m], pred_ind[\u001b[39m0\u001b[39;49m], r, delta[\u001b[39m0\u001b[39;49m])\n",
      "Cell \u001b[0;32mIn[20], line 19\u001b[0m, in \u001b[0;36madd_attributions_to_visualizer\u001b[0;34m(attributions, text, pred, pred_ind, label, delta)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(attributions)\n\u001b[1;32m      9\u001b[0m end_position_vis \u001b[39m=\u001b[39m viz\u001b[39m.\u001b[39mVisualizationDataRecord(\n\u001b[1;32m     10\u001b[0m     attributions, \u001b[39m# word_attributions\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     pred, \u001b[39m# pred_prob\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     delta \u001b[39m# convergence_score\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m viz\u001b[39m.\u001b[39;49mvisualize_text([end_position_vis])\n",
      "File \u001b[0;32m~/Desktop/workspace/proj/dkt-research/env_research/lib/python3.8/site-packages/captum/attr/_utils/visualization.py:863\u001b[0m, in \u001b[0;36mvisualize_text\u001b[0;34m(datarecords, legend)\u001b[0m\n\u001b[1;32m    849\u001b[0m rows \u001b[39m=\u001b[39m [\n\u001b[1;32m    850\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<tr><th>True Label</th>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    851\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<th>Predicted Label</th>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<th>Word Importance</th>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    855\u001b[0m ]\n\u001b[1;32m    856\u001b[0m \u001b[39mfor\u001b[39;00m datarecord \u001b[39min\u001b[39;00m datarecords:\n\u001b[1;32m    857\u001b[0m     rows\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m    859\u001b[0m             [\n\u001b[1;32m    860\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m<tr>\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    861\u001b[0m                 format_classname(datarecord\u001b[39m.\u001b[39mtrue_class),\n\u001b[1;32m    862\u001b[0m                 format_classname(\n\u001b[0;32m--> 863\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39m{0}\u001b[39;49;00m\u001b[39m (\u001b[39;49m\u001b[39m{1:.2f}\u001b[39;49;00m\u001b[39m)\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\n\u001b[1;32m    864\u001b[0m                         datarecord\u001b[39m.\u001b[39;49mpred_class, datarecord\u001b[39m.\u001b[39;49mpred_prob\n\u001b[1;32m    865\u001b[0m                     )\n\u001b[1;32m    866\u001b[0m                 ),\n\u001b[1;32m    867\u001b[0m                 format_classname(datarecord\u001b[39m.\u001b[39mattr_class),\n\u001b[1;32m    868\u001b[0m                 format_classname(\u001b[39m\"\u001b[39m\u001b[39m{0:.2f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(datarecord\u001b[39m.\u001b[39mattr_score)),\n\u001b[1;32m    869\u001b[0m                 format_word_importances(\n\u001b[1;32m    870\u001b[0m                     datarecord\u001b[39m.\u001b[39mraw_input_ids, datarecord\u001b[39m.\u001b[39mword_attributions\n\u001b[1;32m    871\u001b[0m                 ),\n\u001b[1;32m    872\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m<tr>\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    873\u001b[0m             ]\n\u001b[1;32m    874\u001b[0m         )\n\u001b[1;32m    875\u001b[0m     )\n\u001b[1;32m    877\u001b[0m \u001b[39mif\u001b[39;00m legend:\n\u001b[1;32m    878\u001b[0m     dom\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    879\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m<div style=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mborder-top: 1px solid; margin-top: 5px; \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[39m        padding-top: 5px; display: inline-block\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m>\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    881\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/workspace/proj/dkt-research/env_research/lib/python3.8/site-packages/torch/_tensor.py:934\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_meta \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39mis\u001b[39;00m Tensor:\n\u001b[1;32m    933\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem()\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m(format_spec)\n\u001b[0;32m--> 934\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__format__\u001b[39;49m(\u001b[39mself\u001b[39;49m, format_spec)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Tensor.__format__"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        q, r, qshft_seqs, rshft_seqs, mask_seqs, input_ids, token_type_ids, attention_mask, q2diff_seqs, pid_seqs, pidshft_seqs, at_seqs \\\n",
    "            = data\n",
    "        \n",
    "        interpret_sentence(model, q, r, input_ids, token_type_ids, attention_mask)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n",
      "torch.Size([200]) 96\n",
      "16\n",
      "end_position_vis: tensor([ 5306, 39955, 35496, 39962, 29332, 31982, 30962, 32001,  2539,  1367,\n",
      "          129,  1492, 30014, 35219, 29040, 30398,   125, 34207, 32099,   130,\n",
      "        32185,  1429,  1367,   129, 29149, 36278, 17683,  3731, 29355, 29173,\n",
      "        29023, 29163, 29257, 40305, 29161,   130,   130,   129, 40308,   129,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "          100,   100,   100,   100,   100,   100,   100,   100,   100,   100,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 31\u001b[0m\n\u001b[1;32m     21\u001b[0m end_position_vis \u001b[39m=\u001b[39m viz\u001b[39m.\u001b[39mVisualizationDataRecord(\n\u001b[1;32m     22\u001b[0m                 attributions_sum, \u001b[39m# word_attributions\u001b[39;00m\n\u001b[1;32m     23\u001b[0m                 torch\u001b[39m.\u001b[39mmax(torch\u001b[39m.\u001b[39msoftmax(score[\u001b[39m0\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)), \u001b[39m# pred_prob\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 all_tokens[\u001b[39m0\u001b[39m], \u001b[39m# row_input_ids\u001b[39;00m\n\u001b[1;32m     29\u001b[0m                 delta) \u001b[39m# convergence_score\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend_position_vis: \u001b[39m\u001b[39m{\u001b[39;00mindices\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m viz\u001b[39m.\u001b[39;49mvisualize_text([end_position_vis])\n\u001b[1;32m     32\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/workspace/proj/dkt-research/env_research/lib/python3.8/site-packages/captum/attr/_utils/visualization.py:869\u001b[0m, in \u001b[0;36mvisualize_text\u001b[0;34m(datarecords, legend)\u001b[0m\n\u001b[1;32m    849\u001b[0m rows \u001b[39m=\u001b[39m [\n\u001b[1;32m    850\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<tr><th>True Label</th>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    851\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<th>Predicted Label</th>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<th>Word Importance</th>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    855\u001b[0m ]\n\u001b[1;32m    856\u001b[0m \u001b[39mfor\u001b[39;00m datarecord \u001b[39min\u001b[39;00m datarecords:\n\u001b[1;32m    857\u001b[0m     rows\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m    859\u001b[0m             [\n\u001b[1;32m    860\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m<tr>\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    861\u001b[0m                 format_classname(datarecord\u001b[39m.\u001b[39mtrue_class),\n\u001b[1;32m    862\u001b[0m                 format_classname(\n\u001b[1;32m    863\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{1:.2f}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    864\u001b[0m                         datarecord\u001b[39m.\u001b[39mpred_class, datarecord\u001b[39m.\u001b[39mpred_prob\n\u001b[1;32m    865\u001b[0m                     )\n\u001b[1;32m    866\u001b[0m                 ),\n\u001b[1;32m    867\u001b[0m                 format_classname(datarecord\u001b[39m.\u001b[39mattr_class),\n\u001b[1;32m    868\u001b[0m                 format_classname(\u001b[39m\"\u001b[39m\u001b[39m{0:.2f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(datarecord\u001b[39m.\u001b[39mattr_score)),\n\u001b[0;32m--> 869\u001b[0m                 format_word_importances(\n\u001b[1;32m    870\u001b[0m                     datarecord\u001b[39m.\u001b[39;49mraw_input_ids, datarecord\u001b[39m.\u001b[39;49mword_attributions\n\u001b[1;32m    871\u001b[0m                 ),\n\u001b[1;32m    872\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m<tr>\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    873\u001b[0m             ]\n\u001b[1;32m    874\u001b[0m         )\n\u001b[1;32m    875\u001b[0m     )\n\u001b[1;32m    877\u001b[0m \u001b[39mif\u001b[39;00m legend:\n\u001b[1;32m    878\u001b[0m     dom\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    879\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m<div style=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mborder-top: 1px solid; margin-top: 5px; \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[39m        padding-top: 5px; display: inline-block\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m>\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    881\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/workspace/proj/dkt-research/env_research/lib/python3.8/site-packages/captum/attr/_utils/visualization.py:830\u001b[0m, in \u001b[0;36mformat_word_importances\u001b[0;34m(words, importances)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[39mfor\u001b[39;00m word, importance \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(words, importances[: \u001b[39mlen\u001b[39m(words)]):\n\u001b[1;32m    829\u001b[0m     word \u001b[39m=\u001b[39m format_special_tokens(word)\n\u001b[0;32m--> 830\u001b[0m     color \u001b[39m=\u001b[39m _get_color(importance)\n\u001b[1;32m    831\u001b[0m     unwrapped_tag \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m<mark style=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbackground-color: \u001b[39m\u001b[39m{color}\u001b[39;00m\u001b[39m; opacity:1.0; \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[39m                line-height:1.75\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m><font color=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m> \u001b[39m\u001b[39m{word}\u001b[39;00m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    833\u001b[0m \u001b[39m                </font></mark>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m         color\u001b[39m=\u001b[39mcolor, word\u001b[39m=\u001b[39mword\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m     tags\u001b[39m.\u001b[39mappend(unwrapped_tag)\n",
      "File \u001b[0;32m~/Desktop/workspace/proj/dkt-research/env_research/lib/python3.8/site-packages/captum/attr/_utils/visualization.py:793\u001b[0m, in \u001b[0;36m_get_color\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_color\u001b[39m(attr):\n\u001b[1;32m    792\u001b[0m     \u001b[39m# clip values to prevent CSS errors (Values should be from [-1,1])\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m     attr \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mmin\u001b[39;49m(\u001b[39m1\u001b[39;49m, attr))\n\u001b[1;32m    794\u001b[0m     \u001b[39mif\u001b[39;00m attr \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    795\u001b[0m         hue \u001b[39m=\u001b[39m \u001b[39m120\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        q, r, qshft_seqs, rshft_seqs, mask_seqs, input_ids, token_type_ids, attention_mask, q2diff_seqs, pid_seqs, pidshft_seqs, at_seqs \\\n",
    "            = data\n",
    "        print(input_ids.shape)\n",
    "        indices = input_ids[0]\n",
    "        all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "        score = predict(q.long(), r.long(), input_ids, token_type_ids, attention_mask)[0] # sequence 하나만 해보자\n",
    "        print(score.shape, all_tokens[0], )\n",
    "        # acc = [1 if p >= 0.5 else 0 for p in score.detach().cpu().numpy()]\n",
    "        # print(acc, score, r[0][0], torch.argmax(score[0]), input_ids.shape)\n",
    "        attr = LayerIntegratedGradients(predict, model.module.qr_emb_layer)\n",
    "        attributions, delta = attr.attribute((q.long()), additional_forward_args=(r.long(), input_ids, token_type_ids, attention_mask), \\\n",
    "                                    return_convergence_delta=True, n_steps=50, internal_batch_size=16, target=1)\n",
    "        # Assuming attributions is a tensor\n",
    "        print(len(attributions))\n",
    "        attributions_sum = summarize_attributions(attributions)\n",
    "\n",
    "        # attributions_end_sum = summarize_attributions(attributions_end)\n",
    "\n",
    "        end_position_vis = viz.VisualizationDataRecord(\n",
    "                        attributions_sum, # word_attributions\n",
    "                        torch.max(torch.softmax(score[0], dim=0)), # pred_prob\n",
    "                        torch.argmax(score[0]), # pred_class\n",
    "                        torch.argmax(r[0]), # true_class\n",
    "                        str(torch.argmax(score[0])), # attr_class\n",
    "                        attributions_sum.sum(), # attr_score\n",
    "                        all_tokens[0], # row_input_ids\n",
    "                        delta) # convergence_score\n",
    "        print(f\"end_position_vis: {indices}\")\n",
    "        viz.visualize_text([end_position_vis])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 torch.Size([16, 200])\n",
      "512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1.0</b></text></td><td><text style=\"padding-right:2em\"><b>1.0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>tensor(1.)</b></text></td><td><text style=\"padding-right:2em\"><b>-0.01</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 9                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 5                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1.0</b></text></td><td><text style=\"padding-right:2em\"><b>1.0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>tensor(1.)</b></text></td><td><text style=\"padding-right:2em\"><b>-0.01</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 9                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 5                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 12\n",
    "end_position_vis = viz.VisualizationDataRecord(\n",
    "                attributions_sum[index], # word_attributions\n",
    "                score[index], # pred_prob\n",
    "                torch.round(score[index]), # pred_class\n",
    "                r[0][index], # true_class\n",
    "                str(r[0][index]), # attr_class\n",
    "                attributions_sum[index].sum(), # attr_score\n",
    "                all_tokens[index], # row_input_ids\n",
    "                delta) # convergence_score\n",
    "print(f\"{len(attributions_sum)} {r.shape}\")\n",
    "print(f\"{len(all_tokens)}\")\n",
    "viz.visualize_text([end_position_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ U N K ]\n",
      "$1.19  60 99 98 [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "tokenz = ' '.join(all_tokens)\n",
    "tok_data = tokenizer.tokenize(tokenz)\n",
    "print(tokenizer.decode(tokenizer.convert_tokens_to_ids(all_tokens[5])))\n",
    "if '[UNK]' in tok_data:\n",
    "    new_data = tokenizer.convert_tokens_to_ids(tok_data)\n",
    "    print(tokenizer.decode(new_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b9ca63e96671>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqshft_seqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrshft_seqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_seqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq2diff_seqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpid_seqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpidshft_seqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mat_seqs\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        q, r, qshft_seqs, rshft_seqs, mask_seqs, input_ids, token_type_ids, attention_mask, q2diff_seqs, pid_seqs, pidshft_seqs, at_seqs \\\n",
    "            = data\n",
    "        \n",
    "        input_ids = []\n",
    "        ref_input_ids = []\n",
    "        token_type_ids = []\n",
    "        ref_token_type_ids = []\n",
    "        position_ids = []\n",
    "        ref_position_ids = []\n",
    "        attention_masks = []\n",
    "        \n",
    "                \n",
    "        for answer_text in at_seqs:\n",
    "            text = ' '.join(map(str, answer_text))\n",
    "            # print(f\"============= text: {text} ================\")\n",
    "            \n",
    "            input_id, ref_input_id, sep_id = construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id)\n",
    "            token_type_id, ref_token_type_id = construct_input_ref_token_type_pair(input_id, sep_id)\n",
    "            position_id, ref_position_id = construct_input_ref_pos_id_pair(input_id)\n",
    "            attention_mask = construct_attention_mask(input_id)\n",
    "            \n",
    "            input_ids.append(input_id)\n",
    "            ref_input_ids.append(ref_input_id)\n",
    "            token_type_ids.append(token_type_id)\n",
    "            ref_token_type_ids.append(ref_token_type_id)\n",
    "            attention_masks.append(attention_mask)\n",
    "            \n",
    "        # print(input_ids)\n",
    "        input_ids = torch.tensor([t.numpy() for t in input_ids])\n",
    "        print(input_ids)\n",
    "        ref_input_ids = [t.numpy() for t in ref_input_ids]\n",
    "        token_type_ids = [t.numpy() for t in token_type_ids]\n",
    "        ref_token_type_ids = [t.numpy() for t in ref_token_type_ids]\n",
    "        position_ids = [t.numpy() for t in position_ids]\n",
    "        ref_position_ids = [t.numpy() for t in ref_position_ids]\n",
    "        attention_masks = [t.numpy() for t in attention_masks]\n",
    "            \n",
    "        score = predict(q.long(), r.long(), input_ids, token_type_ids, attention_mask)\n",
    "            \n",
    "        indices = input_ids[0].detach().tolist()\n",
    "        all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "        # 워드 임베딩 변화량 볼 수 있음\n",
    "        lig = LayerIntegratedGradients(model, model.module.bertmodel.embeddings)\n",
    "        # attributions_start, delta_start = lig.attribute(inputs=input_ids,\n",
    "        #                         baselines=ref_input_ids,\n",
    "        #                         additional_forward_args=(token_type_ids, position_ids, attention_mask, 0),\n",
    "        #                         return_convergence_delta=True)\n",
    "        # attributions_end, delta_end = lig.attribute(inputs=input_ids, baselines=ref_input_ids,\n",
    "        #                         additional_forward_args=(token_type_ids, position_ids, attention_mask, 1),\n",
    "        #                         return_convergence_delta=True)\n",
    "        \n",
    "        attributions, delta = lig.attribute(inputs=input_ids,\n",
    "                        baselines=ref_input_ids,\n",
    "                        n_steps=700,\n",
    "                        internal_batch_size=3,\n",
    "                        return_convergence_delta=True)\n",
    "        attributions_sum = summarize_attributions(attributions)\n",
    "        # attributions_end_sum = summarize_attributions(attributions_end)\n",
    "        \n",
    "        end_position_vis = viz.VisualizationDataRecord(\n",
    "                        attributions_sum,\n",
    "                        torch.max(torch.softmax(score, dim=0)),\n",
    "                        torch.argmax(score),\n",
    "                        torch.argmax(score),\n",
    "                        str(indices.index(input_ids)),\n",
    "                        attributions_sum.sum(),       \n",
    "                        all_tokens,\n",
    "                        delta)\n",
    "        viz.visualize_text([end_position_vis])\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # print(f\"Affected Text: {all_tokens[torch.argmax(torch.tensor(score[0])) : torch.argmax(torch.tensor(score[-1])) + 1]}\")\n",
    "        \n",
    "\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions[0, attributions[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
